{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLUMNS = [\"age\", \"workclass\", \"edu_level\",\n",
    "           \"marital_status\", \"occupation\", \"relationship\",\n",
    "           \"race\", \"sex\", \"hours_per_week\",\n",
    "           \"native_country\", \"income\"]\n",
    "\n",
    "train_df = pd.read_csv(\n",
    "    filepath_or_buffer=\"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\",\n",
    "    names=COLUMNS,\n",
    "    engine='python',\n",
    "    usecols=[0, 1, 4, 5, 6, 7, 8, 9, 12, 13, 14],\n",
    "    sep=r'\\s*,\\s*',\n",
    "    na_values=\"?\"\n",
    ")\n",
    "\n",
    "test_df = pd.read_csv(\n",
    "    filepath_or_buffer=\"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.test\",\n",
    "    names=COLUMNS,\n",
    "    skiprows=[0],\n",
    "    engine='python',\n",
    "    usecols=[0, 1, 4, 5, 6, 7, 8, 9, 12, 13, 14],\n",
    "    sep=r'\\s*,\\s*',\n",
    "    na_values=\"?\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with missing values\n",
    "train_df = train_df.dropna(how=\"any\", axis=0)\n",
    "test_df = test_df.dropna(how=\"any\", axis=0)\n",
    "\n",
    "# To reduce the complexity, we binarize the attribute\n",
    "# To reduce the complexity, we binarize the attribute\n",
    "\n",
    "\n",
    "def mapping(tuple):\n",
    "    # age, 37\n",
    "    tuple['age'] = 1 if tuple['age'] > 37 else 0\n",
    "    # workclass\n",
    "    tuple['workclass'] = 0 if tuple['workclass'] != 'Private' else 1\n",
    "    # edu-level\n",
    "    tuple['edu_level'] = 1 if tuple['edu_level'] > 9 else 0\n",
    "    # maritial statue\n",
    "    tuple['marital_status'] = 1 if tuple['marital_status'] == \"Married-civ-spouse\" else 0\n",
    "    # occupation\n",
    "    tuple['occupation'] = 1 if tuple['occupation'] == \"Craft-repair\" else 0\n",
    "    # relationship\n",
    "    tuple['relationship'] = 0 if tuple['relationship'] == \"Not-in-family\" else 1\n",
    "    # race\n",
    "    tuple['race'] = 0 if tuple['race'] != \"White\" else 1\n",
    "    # sex\n",
    "    tuple['sex'] = 0 if tuple['sex'] != \"Male\" else 1\n",
    "    # hours per week\n",
    "    tuple['hours_per_week'] = 1 if tuple['hours_per_week'] > 40 else 0\n",
    "    # native country\n",
    "    tuple['native_country'] = 1 if tuple['native_country'] == \"United-States\" else 0\n",
    "    # income\n",
    "    tuple['income'] = 1 if tuple['income'] == '>50K' or tuple['income'] == '>50K.' else 0\n",
    "    return tuple\n",
    "\n",
    "\n",
    "train_df = train_df.apply(mapping, axis=1)\n",
    "test_df = test_df.apply(mapping, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.911875870300378"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[\"native_country\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = torch.from_numpy(train_df.values)\n",
    "test_data = torch.from_numpy(test_df.values)\n",
    "# merge two datasets\n",
    "dataset = torch.cat((train_data,test_data), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset,DataLoader\n",
    "class AdultDataset(Dataset):\n",
    "    def __init__(self, data_set):\n",
    "        self.x = data_set\n",
    "        self.len = data_set.size()[0]\n",
    "    def __getitem__(self,index):\n",
    "        return self.x[index]\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "adultDataset = AdultDataset(dataset)\n",
    "dataLoader = DataLoader(dataset=adultDataset, batch_size=128, shuffle=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a basic Generator\n",
    "\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, f, input_size, hidden_size, output_size):\n",
    "        super(Generator, self).__init__()\n",
    "        self.map1 = nn.Linear(input_size, hidden_size)\n",
    "        self.map2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.map3 = nn.Linear(hidden_size, output_size)\n",
    "        # f is action function\n",
    "        self.f = f\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.map1(x)\n",
    "        x = self.f(x)\n",
    "        x = self.map2(x)\n",
    "        x = self.f(x)\n",
    "        x = self.map3(x)\n",
    "        return x\n",
    "\n",
    "# a basic Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, f, input_size, hidden_size, output_size):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.map1 = nn.Linear(input_size, hidden_size)\n",
    "        self.map2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.map3 = nn.Linear(hidden_size, output_size)\n",
    "        # f is action function\n",
    "        self.f = f\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.f(self.map1(x))\n",
    "        x = self.f(self.map2(x))\n",
    "        return torch.sigmoid(self.map3(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFGAN(nn.Module):\n",
    "    def __init__(self, f):\n",
    "        super(CFGAN, self).__init__()\n",
    "\n",
    "        self.age_net = Generator(\n",
    "            f, 1, 2, 1)\n",
    "        self.workclass_net = Generator(\n",
    "            f, 5, 10, 1)\n",
    "        self.edu_level_net = Generator(\n",
    "            f, 6, 12, 1)\n",
    "        self.marital_status_net = Generator(\n",
    "            f, 5, 10, 1)\n",
    "        self.occupation_net = Generator(\n",
    "            f, 6, 12, 1)\n",
    "        self.relationship_net = Generator(\n",
    "            f, 6, 12, 1)\n",
    "        self.race_net = Generator(\n",
    "            f, 1, 2, 1)\n",
    "        self.sex_net = Generator(\n",
    "            f, 1, 2, 1)\n",
    "        self.hours_per_week_net = Generator(\n",
    "            f, 7, 14, 1)\n",
    "        self.native_country_net = Generator(\n",
    "            f, 1, 2, 1)\n",
    "        self.income_net = Generator(\n",
    "            f, 11, 22, 1)\n",
    "\n",
    "    def forward(self, input, intervention=-1):\n",
    "        name = [\"race\", \"age\", \"sex\", \"native_country\", \"marital_status\",\n",
    "                \"edu_level\", \"occupation\", \"hours_per_week\", \"workclass\", \"relationship\", \"income\"]\n",
    "        Z = dict(zip(name, input.transpose(0, 1).view(len(name), -1, 1)))\n",
    "\n",
    "        # hight = 0 in the graph\n",
    "        # sex should considered about intervention\n",
    "        if(intervention == -1):\n",
    "            self.sex = self.race_net(Z[\"sex\"])\n",
    "        elif(intervention == 0):\n",
    "            self.sex = torch.zeros(Z[\"sex\"].size())\n",
    "        else:\n",
    "            self.sex = torch.ones(Z[\"sex\"].size())\n",
    "        self.age = self.age_net(Z[\"age\"])\n",
    "        self.race = self.sex_net(Z[\"race\"])\n",
    "        self.native_country = self.native_country_net(Z[\"native_country\"])\n",
    "\n",
    "        # hight = 1 in the graph\n",
    "        self.marital_status = self.marital_status_net(torch.cat(\n",
    "            [Z[\"marital_status\"], self.race, self.age,\n",
    "                self.sex, self.native_country], 1\n",
    "        ))\n",
    "\n",
    "        # hight = 2 in the gragh\n",
    "        self.edu_level = self.edu_level_net(torch.cat(\n",
    "            [Z[\"edu_level\"], self.race, self.age, self.sex,\n",
    "                self.native_country, self.marital_status], 1\n",
    "        ))\n",
    "\n",
    "        # hight = 3 in the gragh\n",
    "        self.occupation = self.occupation_net(torch.cat(\n",
    "            [Z[\"occupation\"], self.race, self.age, self.sex,\n",
    "                self.marital_status, self.edu_level], 1\n",
    "        ))\n",
    "\n",
    "        self.hours_per_week = self.hours_per_week_net(torch.cat(\n",
    "            [Z[\"hours_per_week\"], self.race, self.age, self.sex,\n",
    "             self.native_country, self.marital_status, self.edu_level], 1\n",
    "        ))\n",
    "\n",
    "        self.workclass = self.workclass_net(torch.cat(\n",
    "            [Z[\"workclass\"], self.age, self.marital_status,\n",
    "                self.edu_level, self.native_country], 1\n",
    "        ))\n",
    "\n",
    "        self.relationship = self.relationship_net(torch.cat(\n",
    "            [Z[\"relationship\"], self.age, self.sex, self.native_country,\n",
    "                self.marital_status, self.edu_level], 1\n",
    "        ))\n",
    "\n",
    "        # hight = 4 in the gragh\n",
    "\n",
    "        self.income = self.income_net(torch.cat(\n",
    "            [Z[\"income\"], self.race, self.age, self.sex, self.native_country, self.marital_status,\n",
    "                self.edu_level, self.occupation, self.hours_per_week, self.workclass, self.relationship], 1\n",
    "        ))\n",
    "\n",
    "        return torch.cat([self.age, self.workclass, self.edu_level, self.marital_status,\n",
    "        self.occupation, self.relationship, self.race, self.sex,\n",
    "        self.hours_per_week, self.native_country, self.income], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 100\n",
    "g_steps = 5\n",
    "g2_steps = 50\n",
    "batch = 128\n",
    "LR = 0.001\n",
    "print_interval = 1\n",
    "# action function\n",
    "discriminator_activation_function = nn.LeakyReLU(0.2)\n",
    "generator_activation_function = torch.tanh\n",
    "\n",
    "# net init\n",
    "discriminator_1 = Discriminator(\n",
    "    discriminator_activation_function, 11, 64, 1)\n",
    "generator = CFGAN(generator_activation_function)\n",
    "\n",
    "# Binary cross entropy: https://pytorch.org/docs/stable/nn.html?highlight=bceloss#torch.nn.BCELoss\n",
    "criterion = nn.BCELoss()\n",
    "# optim\n",
    "generator_optim = torch.optim.Adam(\n",
    "    generator.parameters(), lr=LR, betas=(0.9, 0.99))\n",
    "discriminator_1_optim = torch.optim.Adam(\n",
    "    discriminator_1.parameters(), lr=LR, betas=(0.9, 0.99))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# debug\n",
    "## test for paramaters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = copy.copy(dataLoader)\n",
    "for real_data in data:\n",
    "\n",
    "    # 1A: Train D1 on real\n",
    "    discriminator_1.zero_grad()\n",
    "    d_real_data = real_data\n",
    "    # real data's lable should be true\n",
    "    d_real_labe = torch.ones(d_real_data.size()[0])\n",
    "    d_real_decision = discriminator_1(d_real_data.float())\n",
    "    d_real_loss = criterion(\n",
    "        torch.squeeze(d_real_decision), d_real_labe)\n",
    "    d_real_loss.backward()\n",
    "\n",
    "    # 1B: Train D1 on fake data\n",
    "    d_fake_data = generator(torch.randn(batch, 11))\n",
    "    # print(d_fake_data.size())\n",
    "    d_fake_lable = torch.zeros(batch)\n",
    "    d_fake_decision = discriminator_1(d_fake_data)\n",
    "    d_fake_loss = criterion(torch.squeeze(\n",
    "        d_fake_decision), d_fake_lable)\n",
    "    d_fake_loss.backward()\n",
    "    # Only optimizes D1's parameters\n",
    "    discriminator_1_optim.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = copy.copy(dataLoader)\n",
    "for real_data in data:\n",
    "\n",
    "    # 1A: Train D1 on real\n",
    "    discriminator_1.zero_grad()\n",
    "    d_real_data = real_data\n",
    "    # real data's lable should be true\n",
    "    d_real_labe = torch.ones(d_real_data.size()[0])\n",
    "    d_real_decision = discriminator_1(d_real_data.float())\n",
    "    d_real_loss = criterion(\n",
    "        torch.squeeze(d_real_decision), d_real_labe)\n",
    "    d_real_loss.backward()\n",
    "\n",
    "    # 1B: Train D1 on fake data\n",
    "    d_fake_data = generator(torch.randn(batch, 11))\n",
    "    # print(d_fake_data.size())\n",
    "    d_fake_lable = torch.zeros(batch)\n",
    "    d_fake_decision = discriminator_1(d_fake_data)\n",
    "    d_fake_loss = criterion(torch.squeeze(\n",
    "        d_fake_decision), d_fake_lable)\n",
    "    d_fake_loss.backward()\n",
    "    # Only optimizes D1's parameters\n",
    "    discriminator_1_optim.step()\n",
    "    \n",
    "    for g_index in range(4):\n",
    "        # Train G on D's response\n",
    "        generator.zero_grad()\n",
    "        g_fake_data = generator(torch.randn(batch, 11))\n",
    "        d_g_fake_decision = discriminator_1(g_fake_data)\n",
    "        g_fake_lable = torch.ones(batch)\n",
    "        g_loss = criterion(torch.squeeze(d_g_fake_decision), g_fake_lable)\n",
    "        g_loss.backward()\n",
    "        generator_optim.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.1253, -0.0360, -0.1340, -0.1488, -0.2294,  0.2546,  0.2110, -0.2229,\n",
      "         -0.0851, -0.3133, -0.0554],\n",
      "        [-0.0318,  0.1591, -0.1530,  0.0957, -0.2356,  0.1763,  0.1169, -0.2250,\n",
      "         -0.0033, -0.3591, -0.0544],\n",
      "        [-0.0186,  0.1610, -0.1391,  0.0399, -0.2191,  0.2612,  0.3327, -0.2050,\n",
      "         -0.1094, -0.2992, -0.0640],\n",
      "        [-0.0609,  0.0481, -0.1449,  0.0693, -0.2487,  0.2059,  0.2075, -0.2491,\n",
      "         -0.0944, -0.2996, -0.0546],\n",
      "        [ 0.0174,  0.1076, -0.1303, -0.0503, -0.2395,  0.2269,  0.3320, -0.0618,\n",
      "         -0.0193, -0.3014, -0.0522],\n",
      "        [ 0.0957,  0.1393, -0.1297, -0.0981, -0.1831,  0.2016,  0.3509, -0.1763,\n",
      "         -0.0739, -0.2546, -0.0613],\n",
      "        [ 0.1455,  0.1808, -0.1272, -0.1302, -0.2531,  0.2288,  0.3741, -0.1687,\n",
      "         -0.0565, -0.2619, -0.0736],\n",
      "        [ 0.1853,  0.0538, -0.1528,  0.0675, -0.2008,  0.2613,  0.1255, -0.2005,\n",
      "         -0.0897, -0.2610, -0.0306],\n",
      "        [ 0.1193,  0.1260, -0.1226,  0.0014, -0.1626,  0.1676,  0.2132, -0.2185,\n",
      "         -0.0394, -0.2089, -0.0245],\n",
      "        [ 0.0548,  0.1423, -0.1302, -0.1158, -0.2348,  0.2840,  0.2829, -0.0155,\n",
      "         -0.1658, -0.3245, -0.0770]], grad_fn=<CatBackward>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.4699],\n",
       "        [0.4710],\n",
       "        [0.4695],\n",
       "        [0.4714],\n",
       "        [0.4712],\n",
       "        [0.4700],\n",
       "        [0.4705],\n",
       "        [0.4700],\n",
       "        [0.4698],\n",
       "        [0.4733],\n",
       "        [0.4686],\n",
       "        [0.4705],\n",
       "        [0.4689],\n",
       "        [0.4707],\n",
       "        [0.4698],\n",
       "        [0.4730],\n",
       "        [0.4693],\n",
       "        [0.4728],\n",
       "        [0.4720],\n",
       "        [0.4722],\n",
       "        [0.4704],\n",
       "        [0.4710],\n",
       "        [0.4717],\n",
       "        [0.4720],\n",
       "        [0.4717],\n",
       "        [0.4712],\n",
       "        [0.4721],\n",
       "        [0.4710],\n",
       "        [0.4695],\n",
       "        [0.4714],\n",
       "        [0.4688],\n",
       "        [0.4714],\n",
       "        [0.4696],\n",
       "        [0.4685],\n",
       "        [0.4692],\n",
       "        [0.4736],\n",
       "        [0.4703],\n",
       "        [0.4710],\n",
       "        [0.4702],\n",
       "        [0.4708],\n",
       "        [0.4685],\n",
       "        [0.4713],\n",
       "        [0.4732],\n",
       "        [0.4697],\n",
       "        [0.4697],\n",
       "        [0.4704],\n",
       "        [0.4696],\n",
       "        [0.4685],\n",
       "        [0.4705],\n",
       "        [0.4723],\n",
       "        [0.4719],\n",
       "        [0.4695],\n",
       "        [0.4691],\n",
       "        [0.4730],\n",
       "        [0.4725],\n",
       "        [0.4713],\n",
       "        [0.4695],\n",
       "        [0.4705],\n",
       "        [0.4717],\n",
       "        [0.4712],\n",
       "        [0.4695],\n",
       "        [0.4697],\n",
       "        [0.4695],\n",
       "        [0.4725],\n",
       "        [0.4717],\n",
       "        [0.4684],\n",
       "        [0.4701],\n",
       "        [0.4698],\n",
       "        [0.4678],\n",
       "        [0.4722],\n",
       "        [0.4716],\n",
       "        [0.4703],\n",
       "        [0.4702],\n",
       "        [0.4689],\n",
       "        [0.4717],\n",
       "        [0.4700],\n",
       "        [0.4696],\n",
       "        [0.4716],\n",
       "        [0.4706],\n",
       "        [0.4703],\n",
       "        [0.4691],\n",
       "        [0.4698],\n",
       "        [0.4699],\n",
       "        [0.4714],\n",
       "        [0.4697],\n",
       "        [0.4723],\n",
       "        [0.4729],\n",
       "        [0.4699],\n",
       "        [0.4698],\n",
       "        [0.4683],\n",
       "        [0.4692],\n",
       "        [0.4700],\n",
       "        [0.4709],\n",
       "        [0.4703],\n",
       "        [0.4715],\n",
       "        [0.4706],\n",
       "        [0.4738],\n",
       "        [0.4719],\n",
       "        [0.4726],\n",
       "        [0.4720],\n",
       "        [0.4691],\n",
       "        [0.4712],\n",
       "        [0.4679],\n",
       "        [0.4680],\n",
       "        [0.4700],\n",
       "        [0.4702],\n",
       "        [0.4707],\n",
       "        [0.4692],\n",
       "        [0.4708],\n",
       "        [0.4723],\n",
       "        [0.4718],\n",
       "        [0.4727],\n",
       "        [0.4698],\n",
       "        [0.4687],\n",
       "        [0.4725],\n",
       "        [0.4709],\n",
       "        [0.4709],\n",
       "        [0.4716],\n",
       "        [0.4729],\n",
       "        [0.4697],\n",
       "        [0.4735],\n",
       "        [0.4703],\n",
       "        [0.4708],\n",
       "        [0.4721],\n",
       "        [0.4690],\n",
       "        [0.4713],\n",
       "        [0.4685],\n",
       "        [0.4695]], grad_fn=<SigmoidBackward>)"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(generator(torch.randn(10, 11)))\n",
    "dis = discriminator_1(generator(torch.randn(batch, 11)))\n",
    "dis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 1,  ..., 1, 1, 0],\n",
       "        [0, 1, 0,  ..., 0, 1, 0],\n",
       "        [1, 1, 1,  ..., 1, 0, 1],\n",
       "        ...,\n",
       "        [1, 1, 0,  ..., 1, 0, 1],\n",
       "        [0, 1, 1,  ..., 0, 1, 0],\n",
       "        [0, 1, 1,  ..., 0, 1, 0]])"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = copy.copy(dataLoader)\n",
    "data = enumerate(data)\n",
    "i ,real_data_0 = data.__next__()\n",
    "real_data_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 11])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_data_0.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000],\n",
       "        [1.0000],\n",
       "        [1.0000],\n",
       "        [1.0000],\n",
       "        [1.0000],\n",
       "        [1.0000],\n",
       "        [1.0000],\n",
       "        [1.0000],\n",
       "        [1.0000],\n",
       "        [1.0000],\n",
       "        [1.0000],\n",
       "        [1.0000],\n",
       "        [1.0000],\n",
       "        [1.0000],\n",
       "        [1.0000],\n",
       "        [1.0000],\n",
       "        [1.0000],\n",
       "        [1.0000],\n",
       "        [1.0000],\n",
       "        [1.0000],\n",
       "        [1.0000],\n",
       "        [1.0000],\n",
       "        [1.0000],\n",
       "        [1.0000],\n",
       "        [1.0000],\n",
       "        [1.0000],\n",
       "        [1.0000],\n",
       "        [1.0000],\n",
       "        [1.0000],\n",
       "        [1.0000],\n",
       "        [1.0000],\n",
       "        [1.0000],\n",
       "        [1.0000],\n",
       "        [1.0000],\n",
       "        [1.0000],\n",
       "        [1.0000],\n",
       "        [1.0000],\n",
       "        [1.0000],\n",
       "        [1.0000],\n",
       "        [1.0000],\n",
       "        [1.0000],\n",
       "        [1.0000],\n",
       "        [1.0000],\n",
       "        [1.0000],\n",
       "        [1.0000],\n",
       "        [1.0000],\n",
       "        [1.0000],\n",
       "        [1.0000],\n",
       "        [1.0000],\n",
       "        [1.0000],\n",
       "        [1.0000],\n",
       "        [1.0000],\n",
       "        [1.0000],\n",
       "        [1.0000],\n",
       "        [1.0000],\n",
       "        [1.0000],\n",
       "        [1.0000],\n",
       "        [1.0000],\n",
       "        [1.0000],\n",
       "        [1.0000],\n",
       "        [1.0000],\n",
       "        [1.0000],\n",
       "        [1.0000],\n",
       "        [1.0000],\n",
       "        [1.0000],\n",
       "        [1.0000],\n",
       "        [1.0000],\n",
       "        [1.0000],\n",
       "        [1.0000],\n",
       "        [1.0000],\n",
       "        [1.0000],\n",
       "        [1.0000],\n",
       "        [1.0000],\n",
       "        [1.0000],\n",
       "        [1.0000],\n",
       "        [1.0000],\n",
       "        [1.0000],\n",
       "        [1.0000],\n",
       "        [1.0000],\n",
       "        [1.0000],\n",
       "        [1.0000],\n",
       "        [1.0000],\n",
       "        [1.0000],\n",
       "        [1.0000],\n",
       "        [1.0000],\n",
       "        [1.0000],\n",
       "        [1.0000],\n",
       "        [1.0000],\n",
       "        [1.0000],\n",
       "        [1.0000],\n",
       "        [1.0000],\n",
       "        [1.0000],\n",
       "        [1.0000],\n",
       "        [1.0000],\n",
       "        [1.0000],\n",
       "        [1.0000],\n",
       "        [1.0000],\n",
       "        [1.0000],\n",
       "        [1.0000],\n",
       "        [1.0000],\n",
       "        [1.0000],\n",
       "        [1.0000],\n",
       "        [1.0000],\n",
       "        [1.0000],\n",
       "        [1.0000],\n",
       "        [1.0000],\n",
       "        [1.0000],\n",
       "        [1.0000],\n",
       "        [1.0000],\n",
       "        [1.0000],\n",
       "        [1.0000],\n",
       "        [1.0000],\n",
       "        [1.0000],\n",
       "        [1.0000],\n",
       "        [1.0000],\n",
       "        [1.0000],\n",
       "        [1.0000],\n",
       "        [1.0000],\n",
       "        [1.0000],\n",
       "        [1.0000],\n",
       "        [1.0000],\n",
       "        [1.0000],\n",
       "        [1.0000],\n",
       "        [1.0000],\n",
       "        [1.0000],\n",
       "        [1.0000],\n",
       "        [1.0000],\n",
       "        [1.0000]], grad_fn=<SigmoidBackward>)"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "discriminator_1(real_data_0.float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    " for g_index in range(300):\n",
    "    # Train G on D's response\n",
    "    generator.zero_grad()\n",
    "    g_fake_data = generator(torch.randn(batch, 11))\n",
    "    d_g_fake_decision = discriminator_1(g_fake_data)\n",
    "    g_fake_lable = torch.ones(batch)\n",
    "    g_loss = criterion(torch.squeeze(d_g_fake_decision), g_fake_lable)\n",
    "    g_loss.backward()\n",
    "    generator_optim.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: D (0.22125402092933655 real_err, 0.059217192232608795 fake_err) G_l (0.015695534646511078 err) G_0l (None) G_1l (None) G_2l (0.07190127670764923) G_3l (0.07072243094444275);\n",
      "Epoch 1: D (0.8784480094909668 real_err, 0.14986123144626617 fake_err) G_l (0.05311468243598938 err) G_0l (None) G_1l (None) G_2l (None) G_3l (0.04634556174278259);\n",
      "Epoch 2: D (0.32248008251190186 real_err, 0.18921847641468048 fake_err) G_l (0.010749738663434982 err) G_0l (None) G_1l (None) G_2l (None) G_3l (0.06491663306951523);\n",
      "Epoch 3: D (0.2830143868923187 real_err, 0.25805848836898804 fake_err) G_l (0.02052653394639492 err) G_0l (None) G_1l (None) G_2l (None) G_3l (0.029447432607412338);\n",
      "Epoch 4: D (0.08148318529129028 real_err, 0.15486261248588562 fake_err) G_l (0.0037686177529394627 err) G_0l (None) G_1l (None) G_2l (None) G_3l (0.09675496816635132);\n",
      "Epoch 5: D (0.6273917555809021 real_err, 0.5055474638938904 fake_err) G_l (0.02917487919330597 err) G_0l (None) G_1l (None) G_2l (None) G_3l (0.030271584168076515);\n",
      "Epoch 6: D (0.49867790937423706 real_err, 0.5175061225891113 fake_err) G_l (0.3499322235584259 err) G_0l (None) G_1l (None) G_2l (None) G_3l (0.0468820184469223);\n",
      "Epoch 7: D (0.4130099415779114 real_err, 0.2603578567504883 fake_err) G_l (0.0016336796106770635 err) G_0l (None) G_1l (None) G_2l (None) G_3l (0.08965965360403061);\n",
      "Epoch 8: D (0.5100611448287964 real_err, 0.34230339527130127 fake_err) G_l (0.10457960516214371 err) G_0l (None) G_1l (None) G_2l (None) G_3l (0.01652887836098671);\n",
      "Epoch 9: D (0.5397396683692932 real_err, 0.16634927690029144 fake_err) G_l (0.0007370166131295264 err) G_0l (None) G_1l (None) G_2l (None) G_3l (0.028134718537330627);\n",
      "Epoch 10: D (0.4859308898448944 real_err, 0.34623533487319946 fake_err) G_l (0.00014762203500140458 err) G_0l (None) G_1l (None) G_2l (None) G_3l (0.32949814200401306);\n",
      "Epoch 11: D (0.2175847291946411 real_err, 0.17840856313705444 fake_err) G_l (0.06142515689134598 err) G_0l (None) G_1l (None) G_2l (None) G_3l (0.25313279032707214);\n",
      "Epoch 12: D (0.5938618183135986 real_err, 0.30312445759773254 fake_err) G_l (0.0015326347202062607 err) G_0l (None) G_1l (None) G_2l (None) G_3l (0.5732567310333252);\n",
      "Epoch 13: D (0.3207414150238037 real_err, 0.13182073831558228 fake_err) G_l (0.05894848331809044 err) G_0l (None) G_1l (None) G_2l (None) G_3l (0.5374412536621094);\n",
      "Epoch 14: D (0.16929370164871216 real_err, 0.1976919323205948 fake_err) G_l (0.47929638624191284 err) G_0l (None) G_1l (None) G_2l (None) G_3l (0.3470424711704254);\n",
      "Epoch 15: D (0.11231118440628052 real_err, 0.048068709671497345 fake_err) G_l (4.9841088184621185e-05 err) G_0l (None) G_1l (None) G_2l (None) G_3l (0.6881944537162781);\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-3e16d4c23e2b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mg_fake_lable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mg_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_g_fake_decision\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg_fake_lable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0mg_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m         \u001b[0mgenerator_optim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mgl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mg_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    164\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \"\"\"\n\u001b[0;32m--> 166\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import copy\n",
    "for epoch in range(num_epochs):\n",
    "    # GAN1\n",
    "    # 1. Train D on real+fake\n",
    "    # D.zero_grad()\n",
    "    data = copy.copy(dataLoader)\n",
    "\n",
    "    for real_data in data:\n",
    "\n",
    "        # 1A: Train D1 on real\n",
    "        discriminator_1.zero_grad()\n",
    "        d_real_data = real_data\n",
    "        # real data's lable should be true\n",
    "        d_real_labe = torch.ones(d_real_data.size()[0])\n",
    "        d_real_decision = discriminator_1(d_real_data.float())\n",
    "        d_real_loss = criterion(\n",
    "            torch.squeeze(d_real_decision), d_real_labe)\n",
    "        d_real_loss.backward()\n",
    "\n",
    "        # 1B: Train D1 on fake data\n",
    "        d_fake_data = generator(torch.randn(batch, 11))\n",
    "        # print(d_fake_data.size())\n",
    "        d_fake_lable = torch.zeros(batch)\n",
    "        d_fake_decision = discriminator_1(d_fake_data)\n",
    "        d_fake_loss = criterion(torch.squeeze(\n",
    "            d_fake_decision), d_fake_lable)\n",
    "        d_fake_loss.backward()\n",
    "        # Only optimizes D1's parameters\n",
    "        discriminator_1_optim.step()\n",
    "\n",
    "        drl, dfl = d_real_loss.tolist(), d_fake_loss.tolist()\n",
    "    for g_index in range(g_steps):\n",
    "        # Train G on D's response\n",
    "        generator.zero_grad()\n",
    "\n",
    "        g_fake_data = generator(torch.randn(batch, 11))\n",
    "        d_g_fake_decision = discriminator_1(g_fake_data)\n",
    "        g_fake_lable = torch.ones(batch)\n",
    "        g_loss = criterion(torch.squeeze(d_g_fake_decision), g_fake_lable)\n",
    "        g_loss.backward()\n",
    "        generator_optim.step()\n",
    "        gl = g_loss.tolist()\n",
    "\n",
    "    # GAN2\n",
    "    for g_index in range(g2_steps):\n",
    "        generator.zero_grad()\n",
    "        noise_z = torch.randn(batch, 11)\n",
    "        fake_data = generator(noise_z)\n",
    "        # O = {race; native country}:(0,0) (0,1) (1,0) (1,1)\n",
    "        noise_o0 = []\n",
    "        noise_o1 = []\n",
    "        noise_o2 = []\n",
    "        noise_o3 = []\n",
    "\n",
    "        for index, single_data in enumerate(fake_data):\n",
    "            if(single_data[7] < 0.5 and single_data[9] < 0.5):\n",
    "                noise_o0.append(noise_z[index].view(1, -1))\n",
    "            elif(single_data[7] < 0.5 and single_data[9] >= 0.5):\n",
    "                noise_o1.append(noise_z[index].view(1, -1))\n",
    "            elif(single_data[7] >= 0.5 and single_data[9] < 0.5):\n",
    "                noise_o2.append(noise_z[index].view(1, -1))\n",
    "            else:\n",
    "                noise_o3.append(noise_z[index].view(1, -1))\n",
    "        ge0,ge1,ge2,ge3 = None,None,None,None\n",
    "        if(len(noise_o0) != 0):\n",
    "            noise_o0 = torch.cat(noise_o0)\n",
    "            o0_0_lable = generator(noise_o0, 0)[:, -1]\n",
    "            o0_1_lable = generator(noise_o0, 1)[:, -1].detach()\n",
    "            g_error0 = criterion(o0_0_lable, o0_1_lable)\n",
    "            g_error0.backward()\n",
    "            ge0 = g_error0.tolist()\n",
    "        if(len(noise_o1) != 0):\n",
    "            noise_o1 = torch.cat(noise_o1)\n",
    "            o1_0_lable = generator(noise_o1, 0)[:, -1]\n",
    "            o1_1_lable = generator(noise_o1, 1)[:, -1].detach()\n",
    "            g_error1 = criterion(o1_0_lable, o1_1_lable)\n",
    "            g_error1.backward()\n",
    "            ge1 = g_error1.tolist()\n",
    "        if(len(noise_o2) != 0):\n",
    "            noise_o2 = torch.cat(noise_o2)\n",
    "            o2_0_lable = generator(noise_o2, 0)[:, -1]\n",
    "            o2_1_lable = generator(noise_o2, 1)[:, -1].detach()\n",
    "            g_error2 = criterion(o2_0_lable, o2_1_lable)\n",
    "            g_error2.backward()\n",
    "            ge2 = g_error2.tolist()\n",
    "        if(len(noise_o3) != 0):\n",
    "            noise_o3 = torch.cat(noise_o3)\n",
    "            o3_0_lable = generator(noise_o3, 0)[:, -1]\n",
    "            o3_1_lable = generator(noise_o3, 1)[:, -1].detach()\n",
    "            g_error3 = criterion(o3_0_lable, o3_1_lable)\n",
    "            g_error3.backward()\n",
    "            ge3 = g_error3.tolist()\n",
    "\n",
    "        generator_optim.step()\n",
    "\n",
    "    if epoch % print_interval == 0:\n",
    "        print(\"Epoch %s: D (%s real_err, %s fake_err) G_l (%s err) G_0l (%s) G_1l (%s) G_2l (%s) G_3l (%s);\" % (\n",
    "            epoch, drl, dfl, gl, ge0, ge1, ge2, ge3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit ('anaconda3': conda)",
   "language": "python",
   "name": "python37464bitanaconda3conda5df9da8887984ee4b635526a125f85b2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
